{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7036a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dset.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import chess\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dset\n",
    "import net\n",
    "import autoencoder\n",
    "import bitboards\n",
    "\n",
    "c_const = 0.5\n",
    "samplingRate = 0.4\n",
    "seed = random.randint(0, 100)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    loss = nn.BCELoss()    \n",
    "    y_hat_concat = torch.cat((y_hat[0], y_hat[1]), 1)\n",
    "    \n",
    "    return loss(y_hat_concat, y)\n",
    "\n",
    "def train_mcts(batch, dataset_size, encoder, nnet, optimizer, reinf, game_generator, *args):\n",
    "    dataset = dset.SearchDataset(dataset_size, dset.Encode(encoder), reinf, game_generator, *args)\n",
    "    pick = math.floor(samplingRate*len(dataset))\n",
    "    subset = torch.utils.data.random_split(dataset, [pick, len(dataset) - pick], generator=torch.Generator().manual_seed(seed))\n",
    "    \n",
    "    DataLoader = torch.utils.data.DataLoader(subset[0], batch_size=batch, shuffle=True, drop_last=True)\n",
    "    \n",
    "    noBatch = 0\n",
    "    running_loss, running_mse, running_cross_entropy = 0, 0, 0\n",
    "    for embedding, value, policy in DataLoader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        value_hat, policy_hat = nnet(embedding.view(embedding.shape[0],1, 256))\n",
    "        mse_value = mse(value_hat, value)\n",
    "        cross_entropy_value = cross_entropy(policy_hat, policy)\n",
    "        loss = c_const * mse_value + (1 - c_const) * cross_entropy_value\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_mse += mse_value.item()\n",
    "        running_cross_entropy += cross_entropy_value.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        noBatch += 1\n",
    "    \n",
    "    print(f\"Loss: \\t\", running_loss/noBatch, \"\\n\\t\\t Value loss: \", running_mse/noBatch, \"\\n\\t\\t Policy loss: \", running_cross_entropy/noBatch, end='\\n\\n')\n",
    "\n",
    "        \n",
    "    torch.save(nnet.state_dict(), \"nnet_mcts.pt\")\n",
    "                \n",
    "def train_alpha_beta(batch, dataset_size, encoder, nnet, optimizer, reinf, game_generator, *args):\n",
    "    dataset = dset.SearchDataset(dataset_size, dset.Encode(encoder), reinf, game_generator, *args)\n",
    "    pick = math.floor(samplingRate*len(dataset))\n",
    "    subset = torch.utils.data.random_split(dataset, [pick, len(dataset) - pick], generator=torch.Generator().manual_seed(seed))\n",
    "    \n",
    "    DataLoader = torch.utils.data.DataLoader(subset[0], batch_size=batch, shuffle=True, drop_last=True)\n",
    "    \n",
    "    noBatch = 0\n",
    "    for embedding, value in DataLoader:\n",
    "        optimizer.zero_grad()\n",
    "        value_hat = nnet(embedding.view(embedding.shape[0],1, 256))\n",
    "\n",
    "        mse_value = mse(value_hat, value)\n",
    "        print(f\"Loss ({noBatch}): \", mse_value.item(), end='\\n')\n",
    "\n",
    "        mse_loss.backward()\n",
    "        optimizer.step()\n",
    "        noBatch += 1\n",
    "        \n",
    "    torch.save(nnet.state_dict(), \"nnet_alpha_beta.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4023221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mputo/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: \t 0.16193206837544075 \n",
      "\t\t Value loss:  0.2434749832520118 \n",
      "\t\t Policy loss:  0.08038915579135601\n",
      "\n",
      "Loss: \t 0.16637234638134638 \n",
      "\t\t Value loss:  0.25227900967001915 \n",
      "\t\t Policy loss:  0.08046568309267361\n",
      "\n",
      "Loss: \t 0.166471799214681 \n",
      "\t\t Value loss:  0.2524803876876831 \n",
      "\t\t Policy loss:  0.08046321012079716\n",
      "\n",
      "Loss: \t 0.1652719428141912 \n",
      "\t\t Value loss:  0.25008121877908707 \n",
      "\t\t Policy loss:  0.08046266809105873\n",
      "\n",
      "Loss: \t 0.1575735198954741 \n",
      "\t\t Value loss:  0.23468338822325072 \n",
      "\t\t Policy loss:  0.08046364970505238\n",
      "\n",
      "Loss: \t 0.15115154658754668 \n",
      "\t\t Value loss:  0.22192280739545822 \n",
      "\t\t Policy loss:  0.08038028702139854\n",
      "\n",
      "Loss: \t 0.16519233584403992 \n",
      "\t\t Value loss:  0.2499204513927301 \n",
      "\t\t Policy loss:  0.08046421781182289\n",
      "\n",
      "Loss: \t 0.16437221834292778 \n",
      "\t\t Value loss:  0.24835808002031767 \n",
      "\t\t Policy loss:  0.08038635208056523\n",
      "\n",
      "Loss: \t 0.1652281110485395 \n",
      "\t\t Value loss:  0.24999184533953667 \n",
      "\t\t Policy loss:  0.08046437799930573\n",
      "\n",
      "Loss: \t 0.16750573987762132 \n",
      "\t\t Value loss:  0.2545459493994713 \n",
      "\t\t Policy loss:  0.0804655309766531\n",
      "\n",
      "Loss: \t 0.16514495884378752 \n",
      "\t\t Value loss:  0.24982620775699615 \n",
      "\t\t Policy loss:  0.08046371427675088\n",
      "\n",
      "Loss: \t 0.15889590749373803 \n",
      "\t\t Value loss:  0.23732732007136711 \n",
      "\t\t Policy loss:  0.08046449835483845\n",
      "\n",
      "Loss: \t 0.1648059325913588 \n",
      "\t\t Value loss:  0.24914763495326042 \n",
      "\t\t Policy loss:  0.08046422588328521\n",
      "\n",
      "Loss: \t 0.16580722853541374 \n",
      "\t\t Value loss:  0.25115002195040387 \n",
      "\t\t Policy loss:  0.08046443698306878\n",
      "\n",
      "Loss: \t 0.16517119568127853 \n",
      "\t\t Value loss:  0.24987787237534156 \n",
      "\t\t Policy loss:  0.08046451325599964\n",
      "\n",
      "Loss: \t 0.16541117085860327 \n",
      "\t\t Value loss:  0.25043538212776184 \n",
      "\t\t Policy loss:  0.08038696417441735\n",
      "\n",
      "Loss: \t 0.16514146948854128 \n",
      "\t\t Value loss:  0.24981961026787758 \n",
      "\t\t Policy loss:  0.08046333181361358\n",
      "\n",
      "Loss: \t 0.16519043422662294 \n",
      "\t\t Value loss:  0.24991713005762833 \n",
      "\t\t Policy loss:  0.0804637406881039\n",
      "\n",
      "Loss: \t 0.14672107001145682 \n",
      "\t\t Value loss:  0.21297732492287955 \n",
      "\t\t Policy loss:  0.08046481758356094\n",
      "\n",
      "Loss: \t 0.16589521616697311 \n",
      "\t\t Value loss:  0.25132695337136585 \n",
      "\t\t Policy loss:  0.08046347896258037\n",
      "\n",
      "Loss: \t 0.16522750879327455 \n",
      "\t\t Value loss:  0.24999199931820235 \n",
      "\t\t Policy loss:  0.08046302013099194\n",
      "\n",
      "Loss: \t 0.15848718335231146 \n",
      "\t\t Value loss:  0.23650989929835 \n",
      "\t\t Policy loss:  0.08046446430186431\n",
      "\n",
      "Loss: \t 0.16522134219606718 \n",
      "\t\t Value loss:  0.24997818594177565 \n",
      "\t\t Policy loss:  0.080464497829477\n",
      "\n",
      "Loss: \t 0.15849926695227623 \n",
      "\t\t Value loss:  0.23653549328446388 \n",
      "\t\t Policy loss:  0.08046304062008858\n",
      "\n",
      "Loss: \t 0.16536206809374002 \n",
      "\t\t Value loss:  0.2503389991246737 \n",
      "\t\t Policy loss:  0.08038513706280635\n",
      "\n",
      "Loss: \t 0.1650972801905412 \n",
      "\t\t Value loss:  0.24988580208558303 \n",
      "\t\t Policy loss:  0.08030875600301303\n",
      "\n",
      "Loss: \t 0.1653286596903434 \n",
      "\t\t Value loss:  0.25019268462291133 \n",
      "\t\t Policy loss:  0.08046463762338345\n",
      "\n",
      "Loss: \t 0.16409922792361334 \n",
      "\t\t Value loss:  0.24773739163692182 \n",
      "\t\t Policy loss:  0.08046106363718326\n",
      "\n",
      "Loss: \t 0.17008444322989538 \n",
      "\t\t Value loss:  0.25970945908473086 \n",
      "\t\t Policy loss:  0.08045942794818145\n",
      "\n",
      "Loss: \t 0.1583484594638531 \n",
      "\t\t Value loss:  0.23623485748584455 \n",
      "\t\t Policy loss:  0.08046206144186166\n",
      "\n",
      "Loss: \t 0.15603157877922058 \n",
      "\t\t Value loss:  0.23159952958424887 \n",
      "\t\t Policy loss:  0.08046362486978371\n",
      "\n",
      "Loss: \t 0.16516885285576186 \n",
      "\t\t Value loss:  0.24987586960196495 \n",
      "\t\t Policy loss:  0.08046183176338673\n",
      "\n",
      "Loss: \t 0.16530450557669005 \n",
      "\t\t Value loss:  0.25014593079686165 \n",
      "\t\t Policy loss:  0.08046308532357216\n",
      "\n",
      "Loss: \t 0.16514167934656143 \n",
      "\t\t Value loss:  0.24981863175829253 \n",
      "\t\t Policy loss:  0.08046472755571206\n",
      "\n",
      "Loss: \t 0.1654527224600315 \n",
      "\t\t Value loss:  0.25044261664152145 \n",
      "\t\t Policy loss:  0.08046282889942329\n",
      "\n",
      "Loss: \t 0.1650398694551908 \n",
      "\t\t Value loss:  0.24961655758894408 \n",
      "\t\t Policy loss:  0.0804631790289512\n",
      "\n",
      "Loss: \t 0.16542361562068647 \n",
      "\t\t Value loss:  0.2503853256885822 \n",
      "\t\t Policy loss:  0.08046190326030438\n",
      "\n",
      "Loss: \t 0.16543745765319237 \n",
      "\t\t Value loss:  0.25049154116557193 \n",
      "\t\t Policy loss:  0.08038337586017755\n",
      "\n",
      "Loss: \t 0.15616831527306482 \n",
      "\t\t Value loss:  0.23187171381253463 \n",
      "\t\t Policy loss:  0.08046491214862236\n",
      "\n",
      "Loss: \t 0.16527815163135529 \n",
      "\t\t Value loss:  0.2500924194852511 \n",
      "\t\t Policy loss:  0.08046388253569603\n",
      "\n",
      "Loss: \t 0.1647963784635067 \n",
      "\t\t Value loss:  0.24912913764516512 \n",
      "\t\t Policy loss:  0.08046361928184827\n",
      "\n",
      "Loss: \t 0.15804818645119667 \n",
      "\t\t Value loss:  0.23563331365585327 \n",
      "\t\t Policy loss:  0.08046305738389492\n",
      "\n",
      "Loss: \t 0.16491148620843887 \n",
      "\t\t Value loss:  0.2493575376768907 \n",
      "\t\t Policy loss:  0.08046543287734191\n",
      "\n",
      "Loss: \t 0.16445779676238695 \n",
      "\t\t Value loss:  0.24845188980301222 \n",
      "\t\t Policy loss:  0.08046370620528857\n",
      "\n",
      "Loss: \t 0.1643648768464724 \n",
      "\t\t Value loss:  0.24826625858743986 \n",
      "\t\t Policy loss:  0.08046349634726842\n",
      "\n",
      "Loss: \t 0.15718699370821318 \n",
      "\t\t Value loss:  0.23391114051143327 \n",
      "\t\t Policy loss:  0.08046284380058448\n",
      "\n",
      "Loss: \t 0.16774015625317892 \n",
      "\t\t Value loss:  0.25510431950290996 \n",
      "\t\t Policy loss:  0.08037599734961987\n",
      "\n",
      "Loss: \t 0.16673033627179953 \n",
      "\t\t Value loss:  0.25299764367250294 \n",
      "\t\t Policy loss:  0.08046302944421768\n",
      "\n",
      "Loss: \t 0.16794744009772936 \n",
      "\t\t Value loss:  0.25543052951494855 \n",
      "\t\t Policy loss:  0.08046434943874677\n",
      "\n",
      "Loss: \t 0.16521176571647325 \n",
      "\t\t Value loss:  0.2500420982638995 \n",
      "\t\t Policy loss:  0.08038143316904704\n",
      "\n",
      "Loss: \t 0.16498140742381415 \n",
      "\t\t Value loss:  0.24966801330447197 \n",
      "\t\t Policy loss:  0.08029479905962944\n",
      "\n",
      "Loss: \t 0.16180026158690453 \n",
      "\t\t Value loss:  0.24313916514317194 \n",
      "\t\t Policy loss:  0.08046135554711024\n",
      "\n",
      "Loss: \t 0.16627560804287592 \n",
      "\t\t Value loss:  0.25217708696921665 \n",
      "\t\t Policy loss:  0.08037412849565347\n",
      "\n",
      "Loss: \t 0.1634239281217257 \n",
      "\t\t Value loss:  0.24638812119762102 \n",
      "\t\t Policy loss:  0.08045973380406697\n",
      "\n",
      "Loss: \t 0.16544492170214653 \n",
      "\t\t Value loss:  0.2504295880595843 \n",
      "\t\t Policy loss:  0.0804602528611819\n",
      "\n",
      "Loss: \t 0.16560956463217735 \n",
      "\t\t Value loss:  0.25075863922635716 \n",
      "\t\t Policy loss:  0.08046048879623413\n",
      "\n",
      "Loss: \t 0.16576746478676796 \n",
      "\t\t Value loss:  0.25115760912497836 \n",
      "\t\t Policy loss:  0.08037731610238552\n",
      "\n",
      "Loss: \t 0.16521262434812692 \n",
      "\t\t Value loss:  0.2500412189043485 \n",
      "\t\t Policy loss:  0.08038402578005424\n",
      "\n",
      "Loss: \t 0.15739121536413828 \n",
      "\t\t Value loss:  0.23431792482733727 \n",
      "\t\t Policy loss:  0.08046450403829415\n",
      "\n",
      "Loss: \t 0.15748834724609667 \n",
      "\t\t Value loss:  0.23458939102979806 \n",
      "\t\t Policy loss:  0.08038730231615213\n",
      "\n",
      "Loss: \t 0.16536846871559435 \n",
      "\t\t Value loss:  0.2503516421868251 \n",
      "\t\t Policy loss:  0.08038529352499889\n",
      "\n",
      "Loss: \t 0.16470267451726472 \n",
      "\t\t Value loss:  0.24909745386013618 \n",
      "\t\t Policy loss:  0.0803078946012717\n",
      "\n",
      "Loss: \t 0.15226546799143156 \n",
      "\t\t Value loss:  0.22423875083525976 \n",
      "\t\t Policy loss:  0.08029218949377537\n",
      "\n",
      "Loss: \t 0.17440645052836493 \n",
      "\t\t Value loss:  0.26843084394931793 \n",
      "\t\t Policy loss:  0.0803820605461414\n",
      "\n",
      "Loss: \t 0.15640305555783784 \n",
      "\t\t Value loss:  0.23242146120621607 \n",
      "\t\t Policy loss:  0.08038464990945962\n",
      "\n",
      "Loss: \t 0.16501899292835823 \n",
      "\t\t Value loss:  0.24965420823830825 \n",
      "\t\t Policy loss:  0.0803837776184082\n",
      "\n",
      "Loss: \t 0.16121163964271545 \n",
      "\t\t Value loss:  0.24196225156386694 \n",
      "\t\t Policy loss:  0.08046103082597256\n",
      "\n",
      "Loss: \t 0.16722032676140466 \n",
      "\t\t Value loss:  0.25398067757487297 \n",
      "\t\t Policy loss:  0.08045997346440951\n",
      "\n",
      "Loss: \t 0.1655366818110148 \n",
      "\t\t Value loss:  0.2506116156776746 \n",
      "\t\t Policy loss:  0.08046174794435501\n",
      "\n",
      "Loss: \t 0.1658262862608983 \n",
      "\t\t Value loss:  0.25119084692918336 \n",
      "\t\t Policy loss:  0.08046172100764054\n",
      "\n",
      "Loss: \t 0.165153240164121 \n",
      "\t\t Value loss:  0.24992836887637773 \n",
      "\t\t Policy loss:  0.08037811331450939\n",
      "\n",
      "Loss: \t 0.15815072630842528 \n",
      "\t\t Value loss:  0.23584045842289925 \n",
      "\t\t Policy loss:  0.08046099295218785\n",
      "\n",
      "Loss: \t 0.16456875825921694 \n",
      "\t\t Value loss:  0.24867664774258932 \n",
      "\t\t Policy loss:  0.08046086815496285\n",
      "\n",
      "Loss: \t 0.1659262329339981 \n",
      "\t\t Value loss:  0.25139155238866806 \n",
      "\t\t Policy loss:  0.0804609190672636\n",
      "\n",
      "Loss: \t 0.16554527978102365 \n",
      "\t\t Value loss:  0.2506287954747677 \n",
      "\t\t Policy loss:  0.0804617628455162\n",
      "\n",
      "Loss: \t 0.1651779723664125 \n",
      "\t\t Value loss:  0.2498930754760901 \n",
      "\t\t Policy loss:  0.08046287546555202\n",
      "\n",
      "Loss: \t 0.1652941371385868 \n",
      "\t\t Value loss:  0.2502022087574005 \n",
      "\t\t Policy loss:  0.08038606322728671\n",
      "\n",
      "Loss: \t 0.1647337365608949 \n",
      "\t\t Value loss:  0.24908409210351798 \n",
      "\t\t Policy loss:  0.08038338216451499\n",
      "\n",
      "Loss: \t 0.16575774798790613 \n",
      "\t\t Value loss:  0.25105446328719455 \n",
      "\t\t Policy loss:  0.08046103393038113\n",
      "\n",
      "Loss: \t 0.16516362016017622 \n",
      "\t\t Value loss:  0.2498643547296524 \n",
      "\t\t Policy loss:  0.08046288329821366\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: \t 0.163885818173488 \n",
      "\t\t Value loss:  0.24731109042962393 \n",
      "\t\t Policy loss:  0.08046054343382518\n",
      "\n",
      "Loss: \t 0.16318000165315774 \n",
      "\t\t Value loss:  0.24605478117099175 \n",
      "\t\t Policy loss:  0.0803052238546885\n",
      "\n",
      "Loss: \t 0.16834144982007834 \n",
      "\t\t Value loss:  0.2562218721096332 \n",
      "\t\t Policy loss:  0.08046102638428028\n",
      "\n",
      "Loss: \t 0.16474351860009706 \n",
      "\t\t Value loss:  0.24910198954435495 \n",
      "\t\t Policy loss:  0.08038505052144711\n",
      "\n",
      "Loss: \t 0.16530372574925423 \n",
      "\t\t Value loss:  0.2501450392107169 \n",
      "\t\t Policy loss:  0.08046241228779157\n",
      "\n",
      "Loss: \t 0.16500265896320343 \n",
      "\t\t Value loss:  0.24962020149597755 \n",
      "\t\t Policy loss:  0.08038511528418614\n",
      "\n",
      "Loss: \t 0.1647491569702442 \n",
      "\t\t Value loss:  0.24911535244721633 \n",
      "\t\t Policy loss:  0.08038296149327205\n",
      "\n",
      "Loss: \t 0.16266390222769517 \n",
      "\t\t Value loss:  0.24494393055255598 \n",
      "\t\t Policy loss:  0.0803838733297128\n",
      "\n",
      "Loss: \t 0.16090421607861152 \n",
      "\t\t Value loss:  0.24134745047642633 \n",
      "\t\t Policy loss:  0.08046097824206719\n",
      "\n",
      "Loss: \t 0.17278762658437094 \n",
      "\t\t Value loss:  0.2651154225071271 \n",
      "\t\t Policy loss:  0.08045983376602332\n",
      "\n",
      "Loss: \t 0.1654476420237468 \n",
      "\t\t Value loss:  0.2504342278608909 \n",
      "\t\t Policy loss:  0.08046105790596741\n",
      "\n",
      "Loss: \t 0.15924430514375368 \n",
      "\t\t Value loss:  0.23802627126375833 \n",
      "\t\t Policy loss:  0.0804623377819856\n",
      "\n",
      "Loss: \t 0.16487634984346536 \n",
      "\t\t Value loss:  0.24929276681863344 \n",
      "\t\t Policy loss:  0.08045993458766204\n",
      "\n",
      "Loss: \t 0.1666465000464366 \n",
      "\t\t Value loss:  0.2529100030660629 \n",
      "\t\t Policy loss:  0.08038299358808078\n",
      "\n",
      "Loss: \t 0.15528947984178862 \n",
      "\t\t Value loss:  0.2302015187839667 \n",
      "\t\t Policy loss:  0.08037743841608365\n",
      "\n",
      "Loss: \t 0.16567888855934143 \n",
      "\t\t Value loss:  0.2509804181754589 \n",
      "\t\t Policy loss:  0.0803773608058691\n",
      "\n",
      "Loss: \t 0.16380745048324266 \n",
      "\t\t Value loss:  0.24740507577856383 \n",
      "\t\t Policy loss:  0.08020982642968495\n",
      "\n",
      "Loss: \t 0.16852404549717903 \n",
      "\t\t Value loss:  0.2565859581033389 \n",
      "\t\t Policy loss:  0.08046213599542777\n",
      "\n",
      "Loss: \t 0.16454287331837875 \n",
      "\t\t Value loss:  0.24862412076729995 \n",
      "\t\t Policy loss:  0.08046162586945754\n",
      "\n",
      "Loss: \t 0.15377569074432054 \n",
      "\t\t Value loss:  0.22717472786704698 \n",
      "\t\t Policy loss:  0.0803766530007124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH = 64\n",
    "DATASET_SIZE = 2048\n",
    "\n",
    "encoder = autoencoder.autoencoder().cuda()\n",
    "encoder.load_state_dict(torch.load(\"autoencoderftest2.pt\"))\n",
    "nnet = net.Net().cuda()\n",
    "optimizer = optim.Adam(nnet.parameters(), weight_decay=0.01)\n",
    "    \n",
    "for i in range(0, 100):\n",
    "    ARGS = (chess.Board(), nnet, encoder, dset.SearchType.CUSTOM, 5)\n",
    "    GameGenerator = dset.GameGenerator(128, 0, 0)\n",
    "    train_mcts(BATCH, DATASET_SIZE, encoder, nnet, optimizer, dset.ReinforcementType.MC, GameGenerator, *ARGS)\n",
    "    nnet.load_state_dict(torch.load(\"nnet_mcts.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9093654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
