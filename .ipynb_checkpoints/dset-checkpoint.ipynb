{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257629ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import chess\n",
    "import chess.engine\n",
    "from chess.engine import Cp\n",
    "import helperfuncs\n",
    "import bitboards\n",
    "import net\n",
    "import autoencoder\n",
    "import alphabeta\n",
    "import mctsAZ\n",
    "import mcts_custom\n",
    "\n",
    "engine = chess.engine.SimpleEngine.popen_uci(\"/usr/games/stockfish\")\n",
    "SearchType = Enum('SearchType', 'MINIMAX MCTS CUSTOM')\n",
    "ReinforcementType = Enum('ReinforcementType', 'MC TD PARAM')\n",
    "winner_to_num = {chess.WHITE: 1, chess.BLACK: 0, None: 0.5}\n",
    "\n",
    "class Encode(object):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        return self.encoder.encode(sample)\n",
    "    \n",
    "class SearchDataset(Dataset):\n",
    "    def __init__(self, size, transform, reinf, game_generator, *args):\n",
    "        self.data = game_generator.get_dataset(size, reinf, *args)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.transform(self.data[idx][0])] + self.data[idx][1:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "class GameGenerator:\n",
    "    def __init__(self, max_moves, draw_cutoff, param):\n",
    "        \"\"\"\n",
    "        MAX_MOVES in halfmoves\n",
    "        DRAW_CUTOFF in centipawns\n",
    "        PARAM number in range (0, 1) used in PARAM 'ReinforcementType (simple linear combination of TD and Monte-Carlo learning)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.MAX_MOVES = max_moves\n",
    "        self.DRAW_CUTOFF = draw_cutoff\n",
    "        self.PARAM = param\n",
    "\n",
    "    def get_dataset(self, size, reinf, *args):\n",
    "        \"\"\"Get dataset for NN training no smaller than specified 'size'.\n",
    "        Args are the 'generate_game' function parameters.\"\"\"\n",
    "        \n",
    "        dataset = []\n",
    "\n",
    "        while len(dataset) < size:\n",
    "            #generate a new game\n",
    "            game = self.generate_game(*args)\n",
    "\n",
    "            winner, state =  -1, game[-1].state\n",
    "            \n",
    "            #remove drawing positions\n",
    "            i = 0\n",
    "            while state.can_claim_draw():\n",
    "                state = game[- (1 + i)].state\n",
    "                i += 1\n",
    "\n",
    "            outcome = state.outcome()\n",
    "\n",
    "            #score the game with engine and determine winner based on engine score and draw cutoff\n",
    "            score = engine.analyse(state, chess.engine.Limit(time=1))[\"score\"].white()\n",
    "            if score > Cp(self.DRAW_CUTOFF):\n",
    "                winner = chess.WHITE\n",
    "            elif score < Cp(self.DRAW_CUTOFF):\n",
    "                winner = chess.BLACK\n",
    "            else:\n",
    "                winner = None\n",
    "                \n",
    "            #calculating TD learning targets\n",
    "            td_values = []\n",
    "            for nd in game:\n",
    "                td_values.append(self.get_evaluation(args[3], nd))\n",
    "                \n",
    "            values = []\n",
    "            for i in range(len(td_values)):\n",
    "                if((i+1) == len(td_values)):\n",
    "                    values.append(winner_to_num[winner])\n",
    "                else:\n",
    "                    values.append(td_values[i+1])\n",
    "                    \n",
    "                print(values[i], levels=2)\n",
    "\n",
    "                \n",
    "            for i, nd in enumerate(game):\n",
    "                if args[3] == SearchType.MINIMAX:\n",
    "                    position = bitboards.bitboard_to_cnn_input(bitboards.bitboard(nd.get_node().state)).unsqueeze(0).cuda()\n",
    "                    dataset.append([position, values[i]])\n",
    "\n",
    "                elif args[3] == SearchType.MCTS:\n",
    "                    position = bitboards.bitboard_to_cnn_input(bitboards.bitboard(nd.state)).unsqueeze(0).cuda()\n",
    "                    moves = [move.uci() for move in nd.moves]\n",
    "                    policy = helperfuncs.policy_from_probability([[moves[i], child.actionValue] for i, child in enumerate(nd.childNodes)])\n",
    "                    dataset.append([position, values[i], policy.cuda()])\n",
    "\n",
    "                elif args[3] == SearchType.CUSTOM:\n",
    "                    position = bitboards.bitboard_to_cnn_input(bitboards.bitboard(nd.state)).unsqueeze(0).cuda()\n",
    "                    moves = [move.uci() for move in nd.moves]\n",
    "                    choiceProbability = nd.choiceProbability\n",
    "                    policy = helperfuncs.policy_from_probability([[moves[i], choiceProbability.value(i)] for i in range(len(choiceProbability.x))])\n",
    "                    dataset.append([position, values[i], policy.cuda()])\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def generate_game(self, board, nnet, encoder, search_tree, *args):\n",
    "        \"\"\"Generate the chess game given the starting 'board' position. Args depend on chosen search type. \n",
    "        Three parameters for MINIMAX: depth, lower bound and higher bound of aspiration window.\n",
    "        One parameter for MCTS and CUSTOM: number of rollouts.\"\"\"\n",
    "\n",
    "        game, moves = [], 0\n",
    "\n",
    "        while not self.stop_cond(board, moves):\n",
    "\n",
    "            if search_tree == SearchType.MINIMAX:\n",
    "                node = alphabeta.alphabeta(alphabeta.Node(board), args[0], args[1], args[2], nnet, encoder)\n",
    "                board = node.get_node().state\n",
    "\n",
    "            elif search_tree == SearchType.MCTS:\n",
    "                tree = mctsAZ.Mcts(board, nnet, encoder)\n",
    "                node = tree.search(args[0])\n",
    "                board = node.state\n",
    "\n",
    "            elif search_tree == SearchType.CUSTOM:\n",
    "                tree = mcts_custom.Mcts(board, nnet, encoder)\n",
    "                node = tree.search(args[0])\n",
    "                board = node.state\n",
    "                \n",
    "            tree.print_tree(2)\n",
    "\n",
    "            game.append(node)\n",
    "            moves += 1\n",
    "            \n",
    "        return game\n",
    "\n",
    "    def stop_cond(self, board, moves):\n",
    "        '''Stops the game when it has reached terminal position or more moves than allowed were played.'''\n",
    "        end = False\n",
    "\n",
    "        if board.is_checkmate() or board.is_stalemate() or board.is_insufficient_material():\n",
    "            end = True\n",
    "        elif moves > self.MAX_MOVES:\n",
    "            end = True\n",
    "\n",
    "        return end\n",
    "\n",
    "    \n",
    "    def get_evaluation(self, search_type, node):\n",
    "        '''Gets the node evaluation computed during search.'''            \n",
    "        return node.evaluation\n",
    "    \n",
    "\n",
    "#     def get_value(self, reinf_type, search_type, winner, node):\n",
    "#         if reinf_type == ReinforcementType.MC:\n",
    "#             val = winner_to_num[winner]\n",
    "#         elif reinf_type == ReinforcementType.TD or reinf_type == ReinforcementType.PARAM:\n",
    "#             if search_type == SearchType.MINIMAX:\n",
    "#                 val = node.get_val()[0]\n",
    "#             elif search_type == SearchType.MCTS or search_type == SearchType.CUSTOM:\n",
    "#                 val = node.actionValue\n",
    "\n",
    "#         if reinf_type == ReinforcementType.PARAM:\n",
    "#             val = self.PARAM * val + (1 - self.PARAM) * winner_to_num[winner]\n",
    "\n",
    "#         return torch.Tensor([val]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c4bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* visited: 199, actionValue: 0.507646\n",
      "\t* visited: 10 , actionValue: 0.509109, choiceProbability: 0.103185\n",
      "\t* visited: 5  , actionValue:  0.49031, choiceProbability: 0.036482\n",
      "\t* visited: 8  , actionValue: 0.487378, choiceProbability:  0.02682\n",
      "\t* visited: 7  , actionValue: 0.481156, choiceProbability: 0.026722\n",
      "\t* visited: 8  , actionValue: 0.495283, choiceProbability: 0.029067\n",
      "\t* visited: 8  , actionValue: 0.489985, choiceProbability:  0.02655\n",
      "\t* visited: 13 , actionValue: 0.521813, choiceProbability: 0.022883\n",
      "\t* visited: 13 , actionValue: 0.511621, choiceProbability: 0.098768\n",
      "\t* visited: 12 , actionValue: 0.507984, choiceProbability: 0.090726\n",
      "\t* visited: 8  , actionValue: 0.504631, choiceProbability: 0.028344\n",
      "\t* visited: 9  , actionValue: 0.507316, choiceProbability: 0.028425\n",
      "\t* visited: 11 , actionValue:  0.51001, choiceProbability: 0.023624\n",
      "\t* visited: 4  , actionValue: 0.445211, choiceProbability: 0.030177\n",
      "\t* visited: 15 , actionValue: 0.527745, choiceProbability: 0.109788\n",
      "\t* visited: 8  , actionValue: 0.467585, choiceProbability: 0.101277\n",
      "\t* visited: 13 , actionValue: 0.514102, choiceProbability: 0.021439\n",
      "\t* visited: 8  , actionValue: 0.510344, choiceProbability: 0.031692\n",
      "\t* visited: 6  , actionValue: 0.477086, choiceProbability: 0.137011\n",
      "\t* visited: 4  , actionValue: 0.464097, choiceProbability: 0.032929\n",
      "\t* visited: 9  , actionValue: 0.472188, choiceProbability: 0.089476\n",
      "* visited: 199, actionValue: 0.500785\n",
      "\t* visited: 5  , actionValue:  0.46452, choiceProbability: 0.132452\n",
      "\t* visited: 9  , actionValue: 0.489331, choiceProbability: 0.022941\n",
      "\t* visited: 8  , actionValue: 0.495548, choiceProbability: 0.024746\n",
      "\t* visited: 6  , actionValue: 0.502193, choiceProbability: 0.034298\n",
      "\t* visited: 13 , actionValue: 0.520106, choiceProbability: 0.020126\n",
      "\t* visited: 13 , actionValue: 0.506327, choiceProbability: 0.019041\n",
      "\t* visited: 7  , actionValue: 0.492061, choiceProbability: 0.027431\n",
      "\t* visited: 6  , actionValue: 0.477803, choiceProbability: 0.028007\n",
      "\t* visited: 22 , actionValue: 0.536509, choiceProbability: 0.016764\n",
      "\t* visited: 8  , actionValue: 0.475296, choiceProbability: 0.022193\n",
      "\t* visited: 14 , actionValue: 0.516967, choiceProbability: 0.021584\n",
      "\t* visited: 14 , actionValue: 0.534759, choiceProbability: 0.112264\n",
      "\t* visited: 1  , actionValue: 0.428208, choiceProbability: 0.040971\n",
      "\t* visited: 14 , actionValue: 0.531696, choiceProbability: 0.019641\n",
      "\t* visited: 18 , actionValue: 0.522661, choiceProbability:  0.08552\n",
      "\t* visited: 9  , actionValue:  0.49771, choiceProbability: 0.024876\n",
      "\t* visited: 14 , actionValue:  0.52523, choiceProbability: 0.109998\n",
      "* visited: 199, actionValue: 0.503854\n",
      "\t* visited: 8  , actionValue: 0.485512, choiceProbability:  0.02565\n",
      "\t* visited: 7  , actionValue: 0.479206, choiceProbability: 0.028581\n",
      "\t* visited: 13 , actionValue: 0.517573, choiceProbability: 0.101899\n",
      "\t* visited: 11 , actionValue: 0.490164, choiceProbability: 0.020094\n",
      "\t* visited: 2  , actionValue: 0.435842, choiceProbability: 0.039943\n",
      "\t* visited: 6  , actionValue: 0.464995, choiceProbability: 0.028864\n",
      "\t* visited: 9  , actionValue: 0.490322, choiceProbability: 0.025138\n",
      "\t* visited: 20 , actionValue: 0.538489, choiceProbability: 0.094512\n",
      "\t* visited: 17 , actionValue: 0.527661, choiceProbability: 0.018938\n",
      "\t* visited: 7  , actionValue: 0.481528, choiceProbability: 0.114966\n",
      "\t* visited: 12 , actionValue: 0.504004, choiceProbability: 0.091376\n",
      "\t* visited: 11 , actionValue: 0.512902, choiceProbability: 0.025171\n",
      "\t* visited: 11 , actionValue: 0.514305, choiceProbability: 0.129362\n",
      "\t* visited: 9  , actionValue: 0.505035, choiceProbability: 0.027506\n",
      "\t* visited: 6  , actionValue: 0.477079, choiceProbability: 0.031605\n",
      "\t* visited: 17 , actionValue: 0.542438, choiceProbability: 0.102914\n",
      "\t* visited: 9  , actionValue: 0.499105, choiceProbability: 0.028463\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-13a599c4db3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSearchType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUSTOM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mGameGenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGameGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSearchDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReinforcementType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGameGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-56eb26106ad0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, transform, reinf, game_generator, *args)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSearchDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-56eb26106ad0>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self, size, reinf, *args)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m#generate a new game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mwinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-56eb26106ad0>\u001b[0m in \u001b[0;36mgenerate_game\u001b[0;34m(self, board, nnet, encoder, search_tree, *args)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessengine/mcts_custom.py\u001b[0m in \u001b[0;36mprint_tree\u001b[0;34m(self, levels)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mprint_child_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessengine/mcts_custom.py\u001b[0m in \u001b[0;36mprint_child_nodes\u001b[0;34m(n, levels, tabulation)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildNodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", choiceProbability: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoiceProbability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                     \u001b[0mprint_child_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessengine/mcts_custom.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodify_by_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#checking few basic statistics about generated datasets\n",
    "import statistics\n",
    "\n",
    "encoder = autoencoder.autoencoder().cuda()\n",
    "encoder.load_state_dict(torch.load(\"autoencoderftest2.pt\"))\n",
    "nnet = net.Net().cuda()\n",
    "nnet.load_state_dict(torch.load(\"nnet_mcts.pt\"))\n",
    "\n",
    "args = (chess.Board(), nnet, encoder, SearchType.CUSTOM, 200)\n",
    "GameGenerator = GameGenerator(32, 0, 0)\n",
    "dataset = SearchDataset(64, Encode(encoder), ReinforcementType.MC, GameGenerator, *args)\n",
    "\n",
    "vals, policies, positions = [], [], []\n",
    "for position, val, policy in dataset:\n",
    "    vals.append(val.item())\n",
    "    policies.append(policy)\n",
    "    positions.append(position)\n",
    "\n",
    "print(\"Game result mean: \", statistics.mean(vals), \" Standard deviation: \", statistics.stdev(vals))\n",
    "\n",
    "print(\"Example policy: \", policies[32][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eebc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
