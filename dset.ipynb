{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257629ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimport_ipynb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import chess\n",
    "import chess.engine\n",
    "from chess.engine import Cp\n",
    "import helperfuncs\n",
    "import bitboards\n",
    "import net\n",
    "import autoencoder\n",
    "import alphabeta\n",
    "import mctsAZ\n",
    "import mcts_custom\n",
    "\n",
    "engine = chess.engine.SimpleEngine.popen_uci(\"/bin/stockfish\")\n",
    "SearchType = Enum('SearchType', 'MINIMAX MCTS CUSTOM')\n",
    "ReinforcementType = Enum('ReinforcementType', 'MC TD PARAM')\n",
    "winner_to_num = {chess.WHITE: 1, chess.BLACK: 0, None: 0.5}\n",
    "    \n",
    "class SearchDataset(Dataset):\n",
    "    def __init__(self, size, transoform, reinf, game_generator, *args):\n",
    "        self.data = game_generator.get_dataset(size, reinf, *args)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "class GameGenerator:\n",
    "    def __init__(self, max_moves, draw_cutoff, param, reinf_type):\n",
    "        \"\"\"\n",
    "        MAX_MOVES in halfmoves\n",
    "        DRAW_CUTOFF in centipawns\n",
    "        PARAM number in range (0, 1) used in PARAM 'ReinforcementType (simple linear combination of TD and Monte-Carlo learning)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.MAX_MOVES = max_moves\n",
    "        self.DRAW_CUTOFF = draw_cutoff\n",
    "        self.PARAM = param\n",
    "        self.reinf_type = reinf_type\n",
    "\n",
    "    def get_dataset(self, size, reinf, *args):\n",
    "        \"\"\"\n",
    "        Get dataset for NN training no smaller than specified 'size'.\n",
    "        Args are the 'generate_game' function parameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        dataset = []\n",
    "\n",
    "        while len(dataset) < size:\n",
    "            #generate a new game\n",
    "            game = self.generate_game(*args)\n",
    "            \n",
    "            winner, state =  -1, game[-1].state\n",
    "\n",
    "            #score the game with engine and determine winner based on engine score and draw cutoff\n",
    "            score = engine.analyse(state, chess.engine.Limit(time=1))[\"score\"].white()\n",
    "            if score > Cp(self.DRAW_CUTOFF):\n",
    "                winner = chess.WHITE\n",
    "            elif score < Cp(self.DRAW_CUTOFF):\n",
    "                winner = chess.BLACK\n",
    "            else:\n",
    "                winner = None\n",
    "                \n",
    "            #calculate learning targets\n",
    "            values = []\n",
    "            \n",
    "            if self.reinf_type == ReinforcementType.MC:\n",
    "                for nd in game:\n",
    "                    values.append(winner_to_num[winner])\n",
    "                    \n",
    "            elif self.reinf_type == ReinforcementType.TD:\n",
    "                td_values = []\n",
    "                \n",
    "                for nd in game:\n",
    "                    td_values.append(self.get_evaluation(args[3], nd))\n",
    "                \n",
    "                for i in range(len(td_values)):\n",
    "                    if((i+1) == len(td_values)):\n",
    "                        values.append(winner_to_num[winner])\n",
    "                    else:\n",
    "                        values.append(td_values[i+1])\n",
    "            \n",
    "            elif self.reinf_type == ReinforcementType.PARAM:\n",
    "                for nd in game:\n",
    "                    values.append(self.PARAM * winner_to_num[winner])\n",
    "                \n",
    "                td_values = []\n",
    "                for nd in game:\n",
    "                    td_values.append(self.get_evaluation(args[3], nd))\n",
    "                \n",
    "                for i in range(len(td_values)):\n",
    "                    if((i+1) == len(td_values)):\n",
    "                        values[i] = winner_to_num[winner]\n",
    "                    else:\n",
    "                        values[i] += (1 - self.PARAM) * td_values[i+1]\n",
    "                \n",
    "                    \n",
    "            #create dataset for search type\n",
    "            for i, nd in enumerate(game):\n",
    "                if args[3] == SearchType.MINIMAX:\n",
    "                    position = bitboards.bitboard_to_cnn_input(bitboards.bitboard(nd.get_node().state)).unsqueeze(0).cuda()\n",
    "                    dataset.append([position, values[i]])\n",
    "\n",
    "                elif args[3] == SearchType.MCTS:\n",
    "                    position = bitboards.bitboard_to_cnn_input(bitboards.bitboard(nd.state)).unsqueeze(0).cuda()\n",
    "                    moves = [move.uci() for move in nd.moves]\n",
    "                    policy = helperfuncs.policy_from_probability([[moves[i], child.actionValue] for i, child in enumerate(nd.childNodes)])\n",
    "                    dataset.append([position, values[i], policy.cuda()])\n",
    "\n",
    "                elif args[3] == SearchType.CUSTOM:\n",
    "                    position = bitboards.bitboard_to_cnn_input(bitboards.bitboard(nd.state)).unsqueeze(0).cuda()\n",
    "                    moves = [move.uci() for move in nd.moves]\n",
    "                    choiceProbability = nd.choiceProbability\n",
    "                    policy = helperfuncs.policy_from_probability([[moves[i], choiceProbability.value(i)] for i in range(len(choiceProbability.x))])\n",
    "                    dataset.append([position, values[i], policy.cuda()])\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def generate_game(self, board, nnet, encoder, search_tree, *args):\n",
    "        \"\"\"Generate the chess game given the starting 'board' position. Args depend on chosen search type. \n",
    "        Three parameters for MINIMAX: depth, lower bound and higher bound of aspiration window.\n",
    "        One parameter for MCTS and CUSTOM: number of rollouts.\"\"\"\n",
    "\n",
    "        game, moves = [], 0\n",
    "\n",
    "        while not self.stop_cond(board, moves):\n",
    "\n",
    "            if search_tree == SearchType.MINIMAX:\n",
    "                node = alphabeta.alphabeta(alphabeta.Node(board), args[0], args[1], args[2], nnet, encoder)\n",
    "                board = node.get_node().state\n",
    "\n",
    "            elif search_tree == SearchType.MCTS:\n",
    "                tree = mctsAZ.Mcts(board, nnet, encoder)\n",
    "                node = tree.search(args[0])\n",
    "                board = node.state\n",
    "\n",
    "            elif search_tree == SearchType.CUSTOM:\n",
    "                tree = mcts_custom.Mcts(board, nnet, encoder)\n",
    "                node = tree.search(args[0])\n",
    "                board = node.state\n",
    "                \n",
    "            #tree.print_tree(2)\n",
    "\n",
    "            game.append(node)\n",
    "            moves += 1\n",
    "            \n",
    "        return game\n",
    "\n",
    "    def stop_cond(self, board, moves):\n",
    "        '''Stops the game when it has reached terminal position or more moves than allowed were played.'''\n",
    "        end = False\n",
    "\n",
    "        if board.is_checkmate() or board.is_stalemate() or board.is_insufficient_material():\n",
    "            end = True\n",
    "        elif board.can_claim_draw():\n",
    "            end = True\n",
    "        elif moves > self.MAX_MOVES:\n",
    "            end = True\n",
    "\n",
    "        return end\n",
    "\n",
    "    \n",
    "    def get_evaluation(self, search_type, node):\n",
    "        '''Gets the node evaluation computed during search.'''            \n",
    "        return node.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking few basic statistics about generated datasets\n",
    "import statistics\n",
    "\n",
    "encoder = autoencoder.autoencoder().cuda()\n",
    "encoder.load_state_dict(torch.load(\"autoencoderftest2.pt\"))\n",
    "nnet = net.Net().cuda()\n",
    "nnet.load_state_dict(torch.load(\"nnet_mcts.pt\"))\n",
    "\n",
    "args = (chess.Board(), nnet, encoder, SearchType.CUSTOM, 200)\n",
    "GameGenerator = GameGenerator(32, 0, 0)\n",
    "dataset = SearchDataset(64, Encode(encoder), ReinforcementType.MC, GameGenerator, *args)\n",
    "\n",
    "vals, policies, positions = [], [], []\n",
    "for position, val, policy in dataset:\n",
    "    vals.append(val.item())\n",
    "    policies.append(policy)\n",
    "    positions.append(position)\n",
    "\n",
    "print(\"Game result mean: \", statistics.mean(vals), \" Standard deviation: \", statistics.stdev(vals))\n",
    "\n",
    "print(\"Example policy: \", policies[32][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eebc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
